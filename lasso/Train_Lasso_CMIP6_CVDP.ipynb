{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "266c7882-2bf2-4c71-8775-c6cad741b949",
   "metadata": {},
   "source": [
    "# Train CMIP6 large ensemble regional sea ice data with modes of variability from CVDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47205327-c6fd-470c-bb4b-b970c1cde39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.signal as sig\n",
    "from sklearn import linear_model\n",
    "from sklearn import model_selection\n",
    "import datetime\n",
    "import warnings\n",
    "import dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "49fefda9-f1a9-48db-ab36-4a877c6850ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/u/ssg/ch/usr/jupyterhub/envs/npl-3.7.9/dav/lib/python3.7/site-packages/distributed/node.py:155: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 36235 instead\n",
      "  http_address[\"port\"], self.http_server.port\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://10.12.206.49:38194</li>\n",
       "  <li><b>Dashboard: </b><a href='https://jupyterhub.hpc.ucar.edu/stable/user/cwpowell/proxy/36235/status' target='_blank'>https://jupyterhub.hpc.ucar.edu/stable/user/cwpowell/proxy/36235/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>0</li>\n",
       "  <li><b>Cores: </b>0</li>\n",
       "  <li><b>Memory: </b>0 B</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://10.12.206.49:38194' processes=0 threads=0, memory=0 B>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for running on Casper\n",
    "from dask_jobqueue import PBSCluster\n",
    "from dask.distributed import Client\n",
    "\n",
    "cluster = PBSCluster(cores    = 1,\n",
    "                     memory   = '2GB',\n",
    "                     queue    = 'casper',\n",
    "                     walltime = '00:30:00')\n",
    "\n",
    "cluster.scale(12)\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "005c3af2-7ee3-4862-9b9e-e7ad41c52a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of model names with CVDP >=30 members\n",
    "model_names  = ['CanESM5', 'MIROC6', 'GISS-E2-1-G', 'IPSL-CM6A-LR',\n",
    "                'CNRM-CM6-1', 'NorCPM1'\n",
    "]\n",
    "\n",
    "model_centers = {\n",
    "    'CanESM5':'CCCma', 'MIROC6':'MIROC', 'GISS-E2-1-G':'NASA-GISS',\n",
    "    'IPSL-CM6A-LR':'IPSL', 'CNRM-CM6-1':'CNRM-CERFACS', 'NorCPM1':'NCC',\n",
    "}\n",
    "\n",
    "areacello_paths = {\n",
    "    'CanESM5': '/glade/collections/cmip/CMIP6/ScenarioMIP/CCCma/CanESM5/'\\\n",
    "        +'ssp585/r1i1p1f1/Ofx/areacello/gn/v20190429/areacello/'\\\n",
    "        +'areacello_Ofx_CanESM5_ssp585_r1i1p1f1_gn.nc',\n",
    "    \n",
    "    'MIROC6': '/glade/collections/cmip/CMIP6/CMIP/MIROC/MIROC6/historical/'\\\n",
    "        +'r1i1p1f1/Ofx/areacello/gn/v20190311/areacello/'\\\n",
    "        +'areacello_Ofx_MIROC6_historical_r1i1p1f1_gn.nc',\n",
    "    \n",
    "    'GISS-E2-1-G': '/glade/collections/cmip/CMIP6/CMIP/NASA-GISS/GISS-E2-1-G/'\\\n",
    "        +'piControl/r1i1p1f1/Ofx/areacello/gn/v20180824/areacello/'\\\n",
    "        +'areacello_Ofx_GISS-E2-1-G_piControl_r1i1p1f1_gn.nc',\n",
    "    \n",
    "    'IPSL-CM6A-LR': '/glade/collections/cmip/CMIP6/CMIP/IPSL/IPSL-CM6A-LR/'\\\n",
    "        +'historical/r1i1p1f1/Ofx/areacello/gn/v20180803/areacello/'\\\n",
    "        +'areacello_Ofx_IPSL-CM6A-LR_historical_r1i1p1f1_gn.nc',\n",
    "    \n",
    "    'CNRM-CM6-1': '/glade/collections/cmip/CMIP6/CMIP/CNRM-CERFACS/CNRM-CM6-1/'\\\n",
    "        +'historical/r1i1p1f2/Ofx/areacello/gn/v20180917/areacello/'\\\n",
    "        +'areacello_Ofx_CNRM-CM6-1_historical_r1i1p1f2_gn.nc', \n",
    "    \n",
    "    'NorCPM1': '/glade/work/cwpowell/low-frequency-variability/raw_data/'\\\n",
    "        +'masie_masks/areacello_Ofx_NorCPM1_piControl_r1i1p1f1_gn.nc',\n",
    "    \n",
    "}\n",
    "\n",
    "lat_names = {'CanESM5': 'latitude', 'MIROC6':'latitude', 'GISS-E2-1-G':'lat',\n",
    "             'IPSL-CM6A-LR': 'nav_lat', 'CNRM-CM6-1':'lat', \n",
    "             'NorCPM1': 'latitude',\n",
    "}\n",
    "\n",
    "x_y_names = {'CanESM5':['i','j'], 'MIROC6':['x','y'], \n",
    "             'GISS-E2-1-G':['lat','lon'], 'IPSL-CM6A-LR':['x','y'], \n",
    "             'CNRM-CM6-1':['x','y'], 'NorCPM1':['i','j'],\n",
    "}\n",
    "\n",
    "doi_dict = {'CanESM5':'10.5194/gmd-12-4823-2019', \n",
    "            'MIROC6':'10.5194/gmd-12-2727-2019',\n",
    "            'GISS-E2-1-G':'10.1029/2019MS002025',\n",
    "            'IPSL-CM6A-LR':'10.1029/2019MS002010',\n",
    "            'CNRM-CM6-1':'10.1029/2019MS001683',\n",
    "            'NorCPM1':'10.5194/gmd-12-343-2019',\n",
    "}\n",
    "\n",
    "#split train:~75%, test:~15%, validation:~10% (not used in this analysis)\n",
    "mem_split = {'CanESM5':[47,55,64], 'MIROC6':[36,43,49], \n",
    "             'GISS-E2-1-G':[31,37,42], 'IPSL-CM6A-LR':[23,27,31],\n",
    "             'CNRM-CM6-1':[14,17,20], 'NorCPM1':[21,25,29]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de4bd16-64d5-412e-84ed-1beeaa949a38",
   "metadata": {},
   "source": [
    "## Train the Lasso model on absolute SIC % anomaly values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "615a0363-7fca-4ca4-924b-b180e6d567f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_month(sea_ice_data, variability_data, month_, year_lags, \n",
    "                      train_test, start_end_yr, max_iteration, tolorence,\n",
    "                      model_sel, alphas_list):\n",
    "    '''\n",
    "    Function which trains and tests a lasso model from a single GCM for a\n",
    "    single month of sea ice data and with all CVDP climate variables lagged\n",
    "    as specified\n",
    "        \n",
    "    Input:\n",
    "        sea_ice_data: xarray dataarray  \n",
    "            Lowpass filtered standardized sea ice data e.g. SIC or SIT from\n",
    "            a given model\n",
    "        variability_data: xarray dataarray\n",
    "            Climate variable data for all members from a given model\n",
    "        month_: int\n",
    "            The month of the year, e.g. 1 for January\n",
    "        year_lags: list of ints\n",
    "            List of number of years lagged over which to run the Lasso model\n",
    "        train_test: list of ints\n",
    "            List of the member elements up to element x (inclusive) for the \n",
    "            training data, and from y to z (inclusive) for the testing data, \n",
    "            e.g. [74,90,99] for a 100 member ensemble\n",
    "        start_end_yr: list of ints\n",
    "            List of the starting and ending years of analysis e.g. [1950,2014]\n",
    "            Note that the starting year is that of the sea ice data which does\n",
    "            not change with lag, CVDP data for a 10 year lag would use 1940 to\n",
    "            2004 data\n",
    "        max_iteration: int\n",
    "            The maximum number of iterations for to fit the data for the \n",
    "            Lasso method\n",
    "        tolorence: float\n",
    "            The tolorence of the Lasso iterations\n",
    "        model_sel: str\n",
    "            The type of Lasso model to use e.g. 'cyclic' or 'random'\n",
    "        alphas_list: list of floats\n",
    "            The values of alpha used in the Lasso model e.g. [1.0,1.5,2.0]\n",
    "        \n",
    "    Returns:\n",
    "        tuple of two xarray dataarrays, containing Lasso multiple regression \n",
    "        coefficients and scores\n",
    "    '''\n",
    "    \n",
    "    ##################### reorganize sea ice and CVDP data #####################\n",
    "    #prepare sea ice data for analysis by creating year and month dimensions\n",
    "    #out of the time dimension - uncomment if using time dim not year,month\n",
    "#     sea_ice_year_month = sea_ice_data.sortby('time')\n",
    "\n",
    "#     month_seperate = []\n",
    "#     for i in np.arange(1,13):\n",
    "#         temp_data = sea_ice_year_month.sel(\n",
    "#             time=sea_ice_year_month['time.month']==i)\n",
    "#         temp_data['time'] = np.arange(1920,2015)\n",
    "#         month_seperate.append(temp_data)\n",
    "\n",
    "#     target_data = xr.concat((month_seperate), dim='month')\n",
    "#     target_data['month'] = np.arange(1,13)\n",
    "#     target_data = target_data.rename({'time':'year'})\n",
    "\n",
    "    target_data = sea_ice_data.copy()\n",
    "\n",
    "    #prepare CVDP data for analysis by creating year and month dimensions\n",
    "    #out of the time dimension\n",
    "    CVDP_year_month = variability_data.to_array('variable').sortby('time')\n",
    "\n",
    "    month_seperate = []\n",
    "    for i in np.arange(1,13):\n",
    "        temp_data = CVDP_year_month.sel(\n",
    "            time=CVDP_year_month['time.month']==i)\n",
    "        temp_data['time'] = np.arange(1920,2015)\n",
    "        month_seperate.append(temp_data)\n",
    "\n",
    "    CVDP_data = xr.concat((month_seperate), dim='month')\n",
    "    CVDP_data['month'] = np.arange(1,13)\n",
    "    CVDP_data = CVDP_data.rename({'time':'year'})\n",
    "\n",
    "    # make subsets of the datasets with only members in both sea ice and CVDP\n",
    "    # uncomment if using individual models\n",
    "#     common_mem = np.intersect1d(target_data['member'], CVDP_data['member'])\n",
    "\n",
    "#     target_data = target_data.sel(member=common_mem).sortby('member')\n",
    "#     CVDP_data = CVDP_data.sel(member=common_mem).sortby('member')\n",
    "        \n",
    "    #remove AMOC as only some models contain that data\n",
    "    CVDP_data = CVDP_data.drop_sel(variable='AMOC')\n",
    "    \n",
    "    ######################### begin the lasso training #########################\n",
    "    all_alphas_coefs_train = []\n",
    "    all_alphas_score = []\n",
    "    for alpha_val in alphas_list:\n",
    "\n",
    "        all_lags_coefs_train = []\n",
    "        all_lags_score = []\n",
    "        for lag in year_lags:\n",
    "\n",
    "            all_regions_coefs_train  = []\n",
    "            all_regions_score = []\n",
    "            for region_ in np.arange(1,17):\n",
    "\n",
    "                #preapre the sea ice data (targets) and split into 70% training\n",
    "                #and 10% testing data, ensure member is sorted alphabetically\n",
    "                #and time is sorted chronologically not all Jan, all Feb etc.\n",
    "                target_train = target_data.sortby('member')\n",
    "                target_train = target_train.isel(\n",
    "                    member=slice(0,train_test[0])).sel(month=month_).sel(\n",
    "                    year=slice(str(start_end_yr[0]), str(start_end_yr[1]))).sel(\n",
    "                    region=region_).stack(member_time=('member','year'))\n",
    "                \n",
    "                target_test  = target_data.sortby('member')\n",
    "                target_test  = target_test.isel(\n",
    "                    member=slice(train_test[1], train_test[2])).sel(\n",
    "                    month=month_).sel(\n",
    "                    year=slice(str(start_end_yr[0]), str(start_end_yr[1]))).sel(\n",
    "                    region=region_).stack(member_time=('member','year'))\n",
    "\n",
    "                #prepare the CVDP data into the training and testing data\n",
    "                CVDP_train = []\n",
    "                CVDP_test  = []\n",
    "                for lag_month in np.arange(1,13):\n",
    "                        \n",
    "                    CVDP_month_data = CVDP_data.sortby('member')\n",
    "                    CVDP_month_data = CVDP_month_data.sel(\n",
    "                        month=lag_month).sel(\n",
    "                        year=slice(str(start_end_yr[0]-lag), \n",
    "                                   str(start_end_yr[1]-lag)))\n",
    "                    \n",
    "                    CVDP_train.append(CVDP_month_data.isel(\n",
    "                        member=slice(0,train_test[0])))\n",
    "                    CVDP_test.append(CVDP_month_data.isel(\n",
    "                        member=slice(train_test[1], train_test[2])))\n",
    "                \n",
    "                CVDP_train_stacked = xr.concat((CVDP_train),'month')\n",
    "                \n",
    "                CVDP_train_stacked = CVDP_train_stacked.stack(\n",
    "                    member_time=('member','year')).stack(\n",
    "                    var_month=('variable','month'))\n",
    "                               \n",
    "                CVDP_test_stacked  = xr.concat((CVDP_test),'month')\n",
    "                \n",
    "                CVDP_test_stacked = CVDP_test_stacked.stack(\n",
    "                    member_time=('member','year')).stack(\n",
    "                    var_month=('variable','month'))\n",
    "                \n",
    "                #run the lasso model\n",
    "                lasso_model = linear_model.Lasso(alpha=alpha_val, \n",
    "                                                 max_iter=max_iteration, \n",
    "                                                 tol=tolorence, \n",
    "                                                 selection=model_sel)\n",
    "                \n",
    "                lasso_fit = lasso_model.fit(X=CVDP_train_stacked, \n",
    "                                            y=target_train.T)\n",
    "\n",
    "                #save the trained coefficients and the scores\n",
    "                var_month_coords = [] \n",
    "                for var_name_ in CVDP_month_data['variable'].values:\n",
    "                    for i in np.arange(1,13):\n",
    "                        var_month_coords.append(str(var_name_)+'_'+str(i).zfill(2))\n",
    "                \n",
    "                all_regions_coefs_train.append(xr.DataArray(\n",
    "                    data=lasso_fit.coef_, \n",
    "                    coords={'var_month':var_month_coords}, \n",
    "                    dims=['var_month']))\n",
    "\n",
    "                all_regions_score.append(xr.DataArray(\n",
    "                    data=[lasso_model.score(X=CVDP_train_stacked, \n",
    "                                            y=target_train.T), \n",
    "                          lasso_model.score(X=CVDP_test_stacked, \n",
    "                                            y=target_test.T)],\n",
    "                    coords={'train_test':['train','test']}, \n",
    "                    dims=['train_test'])\n",
    "                )\n",
    "\n",
    "            all_lags_coefs_train.append(xr.concat((all_regions_coefs_train),\n",
    "                                                  dim='region'))\n",
    "            all_lags_score.append(xr.concat((all_regions_score), dim='region'))\n",
    "\n",
    "        all_alphas_coefs_train.append(xr.concat((all_lags_coefs_train),\n",
    "                                                dim='lag'))\n",
    "        all_alphas_score.append(xr.concat((all_lags_score), dim='lag'))\n",
    "        \n",
    "    coefs_xr = xr.concat((all_alphas_coefs_train), dim='alpha')\n",
    "    score_xr = xr.concat((all_alphas_score), dim='alpha')\n",
    "    \n",
    "    coefs_xr['region'] = np.arange(1,17)\n",
    "    coefs_xr['lag'] = year_lags\n",
    "    coefs_xr['alpha'] = alphas_list\n",
    "    \n",
    "    score_xr['region'] = np.arange(1,17)\n",
    "    score_xr['lag'] = year_lags\n",
    "    score_xr['alpha'] = alphas_list\n",
    "    \n",
    "    return(coefs_xr, score_xr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6408ed8b-599b-4bf7-97c6-8694b5d57f85",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-24 22:35:38.114850 MIROC6\n",
      "2022-07-24 22:48:10.117707 IPSL-CM6A-LR\n",
      "2022-07-24 22:52:53.416385 CNRM-CM6-1\n",
      "2022-07-24 22:55:50.307458 NorCPM1\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore') \n",
    "#ignore warnings of Lasso not converging occur for even high iterations and high\n",
    "#tolorences\n",
    "###############################################################################\n",
    "for model_name in ['MIROC6', 'IPSL-CM6A-LR',\n",
    "                'CNRM-CM6-1', 'NorCPM1']:#model_names[1:]:    #run the lasso computations with dask\n",
    "    print(datetime.datetime.now(), model_name)\n",
    "    \n",
    "    CMIP6_data = xr.open_dataset(\n",
    "        '/glade/work/cwpowell/low-frequency-variability/input_data/Regional_'\\\n",
    "        +'SIC_SIT_detrended_lowpass_{}_1920_2014.nc'.format(model_name)\n",
    "    )\n",
    "    \n",
    "    CVDP_data = xr.open_dataset(\n",
    "        '/glade/work/cwpowell/low-frequency-variability/input_data/'\\\n",
    "        +'CVDP_standardized_1920_2014_historical_{}.nc'.format(model_name)\n",
    "    )    \n",
    "    \n",
    "    lasso_compute_list = []\n",
    "    for month_ in np.arange(1,13):\n",
    "        lasso_compute_list.append(dask.delayed(train_model_month)(\n",
    "            sea_ice_data = CMIP6_data['SIT'], variability_data = CVDP_data,\n",
    "            month_ = month_, year_lags = np.arange(2,21), \n",
    "            train_test = mem_split[model_name], start_end_yr = [1941,2014], \n",
    "            max_iteration = 1e4, tolorence = 1e-3, \n",
    "            model_sel = 'random', alphas_list = [1.5,2.0,2.5])\n",
    "                                 )\n",
    "\n",
    "    #do the simultaneous computation on all months \n",
    "    lasso_computed = dask.compute(*lasso_compute_list)\n",
    "\n",
    "    coefs = []\n",
    "    scores = []\n",
    "    for month_ in np.arange(1,13):\n",
    "        coefs.append(lasso_computed[month_-1][0])\n",
    "        scores.append(lasso_computed[month_-1][1])\n",
    "\n",
    "    coefs_xr = xr.concat((coefs), dim='month')\n",
    "    scores_xr = xr.concat((scores), dim='month')\n",
    "\n",
    "    coefs_xr['month'] = np.arange(1,13)\n",
    "    scores_xr['month'] = np.arange(1,13)\n",
    "\n",
    "    coefs_attrs = {\n",
    "        'Description': 'Multiple regression coefficients using the Lasso '\\\n",
    "            +'method, trained on average regional sea ice thickness (SIT) '\\\n",
    "            +'and modes of climate variability for the model '\\\n",
    "            +'{}. Regions as defined for NSIDC MASIE-NH '.format(model_name)\\\n",
    "            +'Version 1, modes of variability are obtained from the Climate '\\\n",
    "            +'Variability Diagnostics Package (CVDP). Training on the first '\\\n",
    "            +'75% of members for each region and month of SIC data for '\\\n",
    "            +'1941-2014 using historical CMIP6 forcing with CVDP data lagged '\\\n",
    "            +'between 2 and 20 years for each month of the mode of '\\\n",
    "            +'variability. Hyperparameters: alpha=[1.5,2.0,2.5], random '\\\n",
    "            +'rather than cyclic Lasso model training, maximum iteration of '\\\n",
    "            +'1e4 and a tolorence of 1e-3.', \n",
    "        'Timestamp'  : str(datetime.datetime.utcnow().strftime(\n",
    "            \"%H:%M UTC %a %Y-%m-%d\")),\n",
    "        'Data source': '{}, doi:{} . '.format(model_name, doi_dict[model_name])\\\n",
    "            +'Climate Variability Diagnostics Package, '\\\n",
    "            +'doi:10.1002/2014EO490002. NSIDC MASIE-NH Regions, '\\\n",
    "            +'doi:10.7265/N5GT5K3K.', \n",
    "        'Analysis'   : 'https://github.com/chrisrwp/low-frequency-variability/'\\\n",
    "            +'blob/main/lasso/Train_CMIP6_CVDP.ipynb'\n",
    "    }\n",
    "\n",
    "    coefs_xr.attrs = coefs_attrs\n",
    "\n",
    "    coefs_xr.to_netcdf('/glade/work/cwpowell/low-frequency-variability/'\\\n",
    "        +'lasso_coefs_scores/SIT_CVDP_Lasso_Coefs_{}_'.format(model_name)\\\n",
    "        +'1941_2014_lag_2_20.nc')\n",
    "\n",
    "    scores_attrs = coefs_attrs.copy()\n",
    "    scores_attrs['Description'] = 'Multiple regression scores using the Lasso '\\\n",
    "            +'method, trained and tested on average regional sea ice '\\\n",
    "            +'thickness (SIT) and modes of climate variability for the'\\\n",
    "            +' model {}. Regions as defined for NSIDC '.format(model_name)\\\n",
    "            +'MASIE-NH Version 1, modes of variability are obtained from the '\\\n",
    "            +'Climate Variability Diagnostics Package (CVDP). Training on the '\\\n",
    "            +'first 75% of members and testing on the final 15% of member for '\\\n",
    "            +'each region and month of SIC data for 1941-2014 using '\\\n",
    "            +'historical CMIP6 forcing with CVDP data lagged between 2 and 20 '\\\n",
    "            +'years for each month of the mode of variability. '\\\n",
    "            +'Hyperparameters: alpha=[1.5,2.0,2.5], random rather than cyclic '\\\n",
    "            +'Lasso model training, maximum iteration of 1e4 and a tolorence '\\\n",
    "            +'of 1e-3.', \n",
    "    scores_xr.attrs = scores_attrs\n",
    "\n",
    "    scores_xr.to_netcdf('/glade/work/cwpowell/low-frequency-variability/'\\\n",
    "        +'lasso_coefs_scores/SIT_CVDP_Lasso_Scores_{}_'.format(model_name)\\\n",
    "        +'1941_2014_lag_2_20.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5236dbf7-fab1-49b4-8d24-a77da62c9bde",
   "metadata": {},
   "source": [
    "## Train the Lasso model on relative SIC % point anomalies from initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "5bb77b42-f137-4845-9dd5-6e2d21dfd628",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model_month_relative(\n",
    "    sea_ice_data, variability_data, month_, year_lags, train_test, \n",
    "    start_end_yr, max_iteration, tolorence, model_sel, alphas_list, relative=False\n",
    "):\n",
    "    '''\n",
    "    Function which trains and tests a lasso model from a single GCM for a\n",
    "    single month of sea ice change from starting point and with all CVDP climate \n",
    "    variables lagged as specified\n",
    "        \n",
    "    Input:\n",
    "        sea_ice_data: xarray dataarray  \n",
    "            Lowpass filtered standardized sea ice data e.g. SIC or SIT from\n",
    "            a given model\n",
    "        variability_data: xarray dataarray\n",
    "            Climate variable data for all members from a given model\n",
    "        month_: int\n",
    "            The month of the year, e.g. 1 for January\n",
    "        year_lags: list of ints\n",
    "            List of number of years lagged over which to run the Lasso model\n",
    "        train_test: list of ints\n",
    "            List of the member elements up to element x (inclusive) for the \n",
    "            training data, and from y to z (inclusive) for the testing data, \n",
    "            e.g. [74,90,99] for a 100 member ensemble\n",
    "        start_end_yr: list of ints\n",
    "            List of the starting and ending years of analysis e.g. [1950,2014]\n",
    "            Note that the starting year is that of the sea ice data which does\n",
    "            not change with lag, CVDP data for a 10 year lag would use 1940 to\n",
    "            2004 data\n",
    "        max_iteration: int\n",
    "            The maximum number of iterations for to fit the data for the \n",
    "            Lasso method\n",
    "        tolorence: float\n",
    "            The tolorence of the Lasso iterations\n",
    "        model_sel: str\n",
    "            The type of Lasso model to use e.g. 'cyclic' or 'random'\n",
    "        alphas_list: list of floats\n",
    "            The values of alpha used in the Lasso model e.g. [1.0,1.5,2.0]\n",
    "        relative: bool\n",
    "            If relative, then sea ice data delta with lag is used rather than\n",
    "            the abosolute SIC % anomaly value\n",
    "        \n",
    "    Returns:\n",
    "        tuple of two xarray dataarrays, containing Lasso multiple regression \n",
    "        coefficients and scores\n",
    "    '''\n",
    "    \n",
    "    ##################### reorganize sea ice and CVDP data #####################\n",
    "    #prepare sea ice data for analysis by creating year and month dimensions\n",
    "    #out of the time dimension - uncomment if using time dim not year,month\n",
    "#     sea_ice_year_month = sea_ice_data.sortby('time')\n",
    "\n",
    "#     month_seperate = []\n",
    "#     for i in np.arange(1,13):\n",
    "#         temp_data = sea_ice_year_month.sel(\n",
    "#             time=sea_ice_year_month['time.month']==i)\n",
    "#         temp_data['time'] = np.arange(1920,2015)\n",
    "#         month_seperate.append(temp_data)\n",
    "\n",
    "#     target_data = xr.concat((month_seperate), dim='month')\n",
    "#     target_data['month'] = np.arange(1,13)\n",
    "#     target_data = target_data.rename({'time':'year'})\n",
    "\n",
    "    target_data = sea_ice_data.copy()\n",
    "    \n",
    "    #prepare CVDP data for analysis by creating year and month dimensions\n",
    "    #out of the time dimension\n",
    "    CVDP_year_month = variability_data.to_array('variable').sortby('time')\n",
    "\n",
    "    month_seperate = []\n",
    "    for i in np.arange(1,13):\n",
    "        temp_data = CVDP_year_month.sel(\n",
    "            time=CVDP_year_month['time.month']==i)\n",
    "        temp_data['time'] = np.arange(1920,2015)\n",
    "        month_seperate.append(temp_data)\n",
    "\n",
    "    CVDP_data = xr.concat((month_seperate), dim='month')\n",
    "    CVDP_data['month'] = np.arange(1,13)\n",
    "    CVDP_data = CVDP_data.rename({'time':'year'})\n",
    "\n",
    "    #make subsets of the datasets with only members in both sea ice and CVDP\n",
    "    common_mem = np.intersect1d(target_data['member'], CVDP_data['member'])\n",
    "\n",
    "    target_data = target_data.sel(member=common_mem).sortby('member')\n",
    "    CVDP_data = CVDP_data.sel(member=common_mem).sortby('member')\n",
    "    \n",
    "    #remove AMOC as only CanESM5 and GISS-E2-1-G contain that data\n",
    "    CVDP_data = CVDP_data.drop_sel(variable='AMOC')\n",
    "    \n",
    "    ######################### begin the lasso training #########################\n",
    "    all_alphas_coefs_train = []\n",
    "    all_alphas_score = []\n",
    "    for alpha_val in alphas_list:\n",
    "\n",
    "        all_lags_coefs_train = []\n",
    "        all_lags_score = []\n",
    "        for lag in year_lags:\n",
    "\n",
    "            all_regions_coefs_train  = []\n",
    "            all_regions_score = []\n",
    "            for region_ in [2,3,4,5,11]:#np.arange(1,17):\n",
    "\n",
    "                #preapre the sea ice data (targets) and split into 70% training\n",
    "                #and 10% testing data, ensure member is sorted alphabetically\n",
    "                #and time is sorted chronologically not all Jan, all Feb etc.\n",
    "                \n",
    "                if relative:\n",
    "                    target_data_ = target_data.sel(\n",
    "                        year=slice(str(start_end_yr[0]),str(start_end_yr[1]))) \\\n",
    "                    - target_data.sel(year=slice(str(start_end_yr[0]-lag),\n",
    "                                                 str(start_end_yr[1]-lag))).values\n",
    "                    \n",
    "                    target_train = target_data_.sortby('member')\n",
    "                    target_train = target_train.isel(\n",
    "                    member=slice(0,train_test[0])).sel(month=month_).sel(\n",
    "                    region=region_).stack(member_time=('member','year'))\n",
    "                    \n",
    "                    target_test  = target_data_.sortby('member')\n",
    "                    target_test  = target_test.isel(\n",
    "                    member=slice(train_test[1], train_test[2])).sel(\n",
    "                    month=month_).sel(\n",
    "                    region=region_).stack(member_time=('member','year'))\n",
    "                    \n",
    "                else:\n",
    "                    target_train = target_data.sortby('member')\n",
    "                    target_train = target_train.isel(\n",
    "                        member=slice(0,train_test[0])).sel(month=month_).sel(\n",
    "                        year=slice(str(start_end_yr[0]), str(start_end_yr[1]))).sel(\n",
    "                        region=region_).stack(member_time=('member','year'))\n",
    "\n",
    "                    target_test  = target_data.sortby('member')\n",
    "                    target_test  = target_test.isel(\n",
    "                        member=slice(train_test[1], train_test[2])).sel(\n",
    "                        month=month_).sel(\n",
    "                        year=slice(str(start_end_yr[0]), str(start_end_yr[1]))).sel(\n",
    "                        region=region_).stack(member_time=('member','year'))\n",
    "\n",
    "                #prepare the CVDP data into the training and testing data\n",
    "                CVDP_train = []\n",
    "                CVDP_test  = []\n",
    "                for lag_month in np.arange(1,13):\n",
    "                        \n",
    "                    CVDP_month_data = CVDP_data.sortby('member')\n",
    "                    CVDP_month_data = CVDP_month_data.sel(\n",
    "                        month=lag_month).sel(\n",
    "                        year=slice(str(start_end_yr[0]-lag), \n",
    "                                   str(start_end_yr[1]-lag)))\n",
    "                    \n",
    "                    CVDP_train.append(CVDP_month_data.isel(\n",
    "                        member=slice(0,train_test[0])))\n",
    "                    CVDP_test.append(CVDP_month_data.isel(\n",
    "                        member=slice(train_test[1], train_test[2])))\n",
    "                \n",
    "                CVDP_train_stacked = xr.concat((CVDP_train),'month')\n",
    "                \n",
    "                CVDP_train_stacked = CVDP_train_stacked.stack(\n",
    "                    member_time=('member','year')).stack(\n",
    "                    var_month=('variable','month'))\n",
    "                               \n",
    "                CVDP_test_stacked  = xr.concat((CVDP_test),'month')\n",
    "                \n",
    "                CVDP_test_stacked = CVDP_test_stacked.stack(\n",
    "                    member_time=('member','year')).stack(\n",
    "                    var_month=('variable','month'))\n",
    "                \n",
    "                #run the lasso model\n",
    "                lasso_model = linear_model.Lasso(alpha=alpha_val, \n",
    "                                                 max_iter=max_iteration, \n",
    "                                                 tol=tolorence, \n",
    "                                                 selection=model_sel)\n",
    "                \n",
    "                lasso_fit = lasso_model.fit(X=CVDP_train_stacked, \n",
    "                                            y=target_train.T)\n",
    "\n",
    "                #save the trained coefficients and the scores\n",
    "                var_month_coords = [] \n",
    "                for var_name_ in CVDP_month_data['variable'].values:\n",
    "                    for i in np.arange(1,13):\n",
    "                        var_month_coords.append(str(var_name_)+'_'+str(i).zfill(2))\n",
    "                \n",
    "                all_regions_coefs_train.append(xr.DataArray(\n",
    "                    data=lasso_fit.coef_, \n",
    "                    coords={'var_month':var_month_coords}, \n",
    "                    dims=['var_month']))\n",
    "\n",
    "                all_regions_score.append(xr.DataArray(\n",
    "                    data=[lasso_model.score(X=CVDP_train_stacked, \n",
    "                                            y=target_train.T), \n",
    "                          lasso_model.score(X=CVDP_test_stacked, \n",
    "                                            y=target_test.T)],\n",
    "                    coords={'train_test':['train','test']}, \n",
    "                    dims=['train_test'])\n",
    "                )\n",
    "\n",
    "            all_lags_coefs_train.append(xr.concat((all_regions_coefs_train),\n",
    "                                                  dim='region'))\n",
    "            all_lags_score.append(xr.concat((all_regions_score), dim='region'))\n",
    "\n",
    "        all_alphas_coefs_train.append(xr.concat((all_lags_coefs_train),\n",
    "                                                dim='lag'))\n",
    "        all_alphas_score.append(xr.concat((all_lags_score), dim='lag'))\n",
    "        \n",
    "    coefs_xr = xr.concat((all_alphas_coefs_train), dim='alpha')\n",
    "    score_xr = xr.concat((all_alphas_score), dim='alpha')\n",
    "    \n",
    "    coefs_xr['region'] = [2,3,4,5,11]\n",
    "    coefs_xr['lag'] = year_lags\n",
    "    coefs_xr['alpha'] = alphas_list\n",
    "    \n",
    "    score_xr['region'] = [2,3,4,5,11]\n",
    "    score_xr['lag'] = year_lags\n",
    "    score_xr['alpha'] = alphas_list\n",
    "    \n",
    "    return(coefs_xr, score_xr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fa9240b-1cfd-46a0-b5e7-afce78f8ac66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-01 15:56:50.277699 CanESM5\n",
      "2022-08-01 15:57:30.318027 MIROC6\n",
      "2022-08-01 15:58:04.216938 IPSL-CM6A-LR\n",
      "2022-08-01 15:58:33.688323 GISS-E2-1-G\n",
      "2022-08-01 15:59:04.909930 CNRM-CM6-1\n",
      "2022-08-01 15:59:29.016283 NorCPM1\n"
     ]
    }
   ],
   "source": [
    "region_coefs = {}\n",
    "region_scores = {}\n",
    "for model_name in ['CanESM5', 'MIROC6', 'IPSL-CM6A-LR', 'GISS-E2-1-G',\n",
    "                   'CNRM-CM6-1', 'NorCPM1']:\n",
    "    \n",
    "    print(datetime.datetime.now(), model_name)\n",
    "    \n",
    "    CMIP6_data = xr.open_dataset(\n",
    "        '/glade/work/cwpowell/low-frequency-variability/input_data/Regional_'\\\n",
    "        +'SIC_SIT_detrended_lowpass_{}_1920_2014.nc'.format(model_name)\n",
    "    )\n",
    "    \n",
    "    CVDP_data = xr.open_dataset(\n",
    "        '/glade/work/cwpowell/low-frequency-variability/input_data/'\\\n",
    "        +'CVDP_standardized_1920_2014_historical_{}.nc'.format(model_name)\n",
    "    )    \n",
    "\n",
    "#N.B. replaced mem_split[model_name] with [14,17,20] to do an initial subsampling test\n",
    "\n",
    "    region_model = train_model_month_relative(\n",
    "        sea_ice_data = CMIP6_data['SIC'], variability_data = CVDP_data,\n",
    "        month_ = 10, year_lags = np.arange(2,21), \n",
    "        train_test = [14,17,20], start_end_yr = [1941,2014], \n",
    "        max_iteration = 1e4, tolorence = 1e-3, \n",
    "        model_sel = 'random', alphas_list = [0.10,0.50,0.75,1.00],\n",
    "        relative=False)\n",
    "    \n",
    "    region_coefs[model_name]= region_model[0]\n",
    "    region_scores[model_name]= region_model[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b694fba-b398-45eb-96ab-09ad234a0bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.Dataset(region_coefs).to_netcdf('/glade/work/cwpowell/'\\\n",
    "    +'low-frequency-variability/lasso_coefs_scores/Subset_regions_SIC_coefs_October_subsamp_20.nc')\n",
    "\n",
    "xr.Dataset(region_scores).to_netcdf('/glade/work/cwpowell/'\\\n",
    "    +'low-frequency-variability/lasso_coefs_scores/Subset_regions_SIC_scores_October_subsamp_20.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d840d6-e975-4b63-a093-0e115440a057",
   "metadata": {},
   "source": [
    "# Train model on first 75% of members of all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44554154-8537-4f37-9d77-2fbbd5f93eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "CMIP6_info = xr.open_dataset(\n",
    "    '/glade/work/cwpowell/low-frequency-variability/raw_data/CMIP6_info/'\\\n",
    "    +'CMIP6_modeling_center_members_doi.nc'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78220add-4380-47c5-ae2d-95188afd156d",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_dict = {\n",
    "    '2' :[1, 1, 0],\n",
    "    '3' :[2, 1, 0],\n",
    "    '4' :[2, 1, 1],\n",
    "    '5' :[3, 1, 1],\n",
    "    '6' :[4, 1, 1],\n",
    "    '10':[7, 2, 1],\n",
    "    '11':[8, 2, 1],\n",
    "    '16':[12,2, 2],\n",
    "    '20':[15,3, 2],\n",
    "    '23':[18,3, 2],\n",
    "    '30':[22,5, 3],\n",
    "    '32':[24,5, 3],\n",
    "    '43':[32,7, 4],\n",
    "    '50':[38,7, 5],\n",
    "    '65':[49,10,6],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2b2f472-0c2f-4491-8dc2-92915d9d44d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWI-CM-1-1-MR File Not Found\n",
      "AWI-ESM-1-1-LR File Not Found\n",
      "CNRM-CM6-1 File Not Found\n",
      "CNRM-CM6-1-HR File Not Found\n",
      "E3SM-1-0 File Not Found\n",
      "GFDL-CM4 File Not Found\n",
      "GISS-E2-1-G-CC File Not Found\n",
      "HadGEM3-GC31-MM File Not Found\n",
      "IITM-ESM File Not Found\n",
      "KACE-1-0-G File Not Found\n",
      "KIOST-ESM File Not Found\n",
      "MCM-UA-1-0 File Not Found\n",
      "NorESM2-LM File Not Found\n"
     ]
    }
   ],
   "source": [
    "#first make a dataset of all CMIP6 and CVDP data\n",
    "#then rename the member coordinate to be \n",
    "\n",
    "var_ = 'SIC'\n",
    "\n",
    "all_CMIP6_data = []\n",
    "all_CVDP_data  = []\n",
    "\n",
    "train_iter = 1000\n",
    "test_iter  = 2000\n",
    "valid_iter = 3000\n",
    "\n",
    "single_mem_count = 0\n",
    "\n",
    "for model_name in CMIP6_info['model'].drop_sel(model='CAS-ESM2-0').values:\n",
    "    try:\n",
    "        CMIP6_data = xr.open_dataset(\n",
    "            '/glade/work/cwpowell/low-frequency-variability/input_data/'\\\n",
    "            +f'Regional_SIC_detrended_lowpass_{model_name}_1920_2014.nc'\n",
    "        )      \n",
    "        \n",
    "        CVDP_data = xr.open_dataset(\n",
    "            '/glade/work/cwpowell/low-frequency-variability/input_data/'\\\n",
    "            +f'CVDP_standardized_1920_2014_historical_{model_name}.nc'\n",
    "        )  \n",
    "        \n",
    "        if model_name == 'CNRM-ESM2-1':\n",
    "            CMIP6_data = CMIP6_data.sel(member=['r11i1p1f2', 'r1i1p1f2', \n",
    "                'r2i1p1f2', 'r3i1p1f2', 'r4i1p1f2', 'r5i1p1f2'])\n",
    "            \n",
    "            CVDP_data = CVDP_data.sel(member=['r11i1p1f2', 'r1i1p1f2', \n",
    "                'r2i1p1f2', 'r3i1p1f2', 'r4i1p1f2', 'r5i1p1f2'])\n",
    "        \n",
    "        elif model_name == 'UKESM1-0-LL':\n",
    "            CMIP6_data = CMIP6_data.drop_sel(member=['r13i1p1f2', 'r14i1p1f2'])\n",
    "            CVDP_data = CVDP_data.drop_sel(member=['r13i1p1f2', 'r14i1p1f2'])\n",
    "            \n",
    "            \n",
    "        CMIP6_data = CMIP6_data[var_].sortby('member')\n",
    "        CVDP_data = CVDP_data.sortby('member')\n",
    "        \n",
    "        #get number of members\n",
    "        num_mem = len(CMIP6_data['member'].values)\n",
    "        \n",
    "        assert len(CMIP6_data['member'].values) == len(CVDP_data['member'].values)\n",
    "        \n",
    "        if num_mem == 1:\n",
    "            single_mem_count +=1\n",
    "            \n",
    "            if single_mem_count+1 % 3 == 0:\n",
    "                test_iter += 1\n",
    "                CMIP6_data['member'] = [test_iter]\n",
    "                CVDP_data['member'] = [test_iter]\n",
    "                \n",
    "            elif single_mem_count % 3 == 0:\n",
    "                valid_iter += 1\n",
    "                CMIP6_data['member'] = [valid_iter]\n",
    "                CVDP_data['member'] = [valid_iter]\n",
    "            \n",
    "            else:\n",
    "                train_iter += 1\n",
    "                CMIP6_data['member'] = [train_iter]\n",
    "                CVDP_data['member'] = [train_iter]\n",
    "                   \n",
    "        else:\n",
    "            mem_list = np.concatenate(\n",
    "                (np.arange(train_iter, train_iter+split_dict[str(num_mem)][0]),\n",
    "                np.arange(test_iter, test_iter+split_dict[str(num_mem)][1]),\n",
    "                np.arange(valid_iter, valid_iter+split_dict[str(num_mem)][2])\n",
    "                )\n",
    "            )\n",
    "\n",
    "            train_iter = train_iter + split_dict[str(num_mem)][0]\n",
    "            test_iter = test_iter + split_dict[str(num_mem)][1]\n",
    "            valid_iter = valid_iter + split_dict[str(num_mem)][2]\n",
    "            \n",
    "            CMIP6_data['member'] = mem_list\n",
    "            CVDP_data['member'] = mem_list\n",
    "            \n",
    "        all_CMIP6_data.append(CMIP6_data)\n",
    "        all_CVDP_data.append(CVDP_data)\n",
    "        \n",
    "    except (FileNotFoundError):\n",
    "        print(model_name, 'File Not Found')\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da363e91-b562-4a78-90ed-58a93fd23a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CMIP6_all_mem = xr.concat((all_CMIP6_data), dim='member').sortby('member')\n",
    "CVDP_all_mem  = xr.concat((all_CVDP_data), dim='member').sortby('member')\n",
    "\n",
    "CMIP6_all_mem.to_netcdf('/glade/work/cwpowell/low-frequency-variability/'\\\n",
    "    +'input_data/Regional_SIC_detrended_lowpass_all_CMIP6_1920_2014.nc')\n",
    "\n",
    "CVDP_all_mem.to_netcdf('/glade/work/cwpowell/low-frequency-variability/'\\\n",
    "    +'input_data/CVDP_standardized_1920_2014_historical_all_CMIP6_1920_2014.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d9455543-587f-4724-a956-b086c6b7a7a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#N.B. takes ~10 minutes to run all members with 2GB x 12 dask workers\n",
    "lasso_compute_list = []\n",
    "for month_ in np.arange(1,13):\n",
    "    lasso_compute_list.append(dask.delayed(train_model_month)(\n",
    "        sea_ice_data = CMIP6_all_mem, variability_data = CVDP_all_mem,\n",
    "        month_ = month_, year_lags = np.arange(2,21), \n",
    "        train_test = [306,307,381], start_end_yr = [1941,2014], \n",
    "        max_iteration = 1e5, tolorence = 1e-3, \n",
    "        model_sel = 'random', alphas_list = [0.001])\n",
    "                             )\n",
    "\n",
    "#do the simultaneous computation on all months \n",
    "lasso_computed = dask.compute(*lasso_compute_list)\n",
    "\n",
    "coefs = []\n",
    "scores = []\n",
    "for month_ in np.arange(1,13):\n",
    "    coefs.append(lasso_computed[month_-1][0])\n",
    "    scores.append(lasso_computed[month_-1][1])\n",
    "\n",
    "coefs_xr = xr.concat((coefs), dim='month')\n",
    "scores_xr = xr.concat((scores), dim='month')\n",
    "\n",
    "coefs_xr['month'] = np.arange(1,13)\n",
    "scores_xr['month'] = np.arange(1,13)\n",
    "\n",
    "coefs_attrs = {\n",
    "    'Description': 'Multiple regression coefficients using the Lasso '\\\n",
    "        +'method, trained on average regional sea ice concentration (SIC) '\\\n",
    "        +'and modes of climate variability for all availible CMIP6 models. '\\\n",
    "        +'Regions as defined for NSIDC MASIE-NH '\\\n",
    "        +'Version 1, modes of variability are obtained from the Climate '\\\n",
    "        +'Variability Diagnostics Package (CVDP). Training on the first '\\\n",
    "        +'75% of members for each region and month of SIC data for '\\\n",
    "        +'1941-2014 using historical CMIP6 forcing with CVDP data lagged '\\\n",
    "        +'between 2 and 20 years for each month of the mode of '\\\n",
    "        +'variability. Hyperparameters: alpha=[0.001], '\\\n",
    "        +'random rather than cyclic Lasso model training, maximum iteration '\\\n",
    "        +'of 1e5 and a tolorence of 1e-3.', \n",
    "    'Timestamp'  : str(datetime.datetime.utcnow().strftime(\n",
    "        \"%H:%M UTC %a %Y-%m-%d\")),\n",
    "    'Data source': 'CMIP6 historical model output, '\\\n",
    "        +'Climate Variability Diagnostics Package, '\\\n",
    "        +'doi:10.1002/2014EO490002. NSIDC MASIE-NH Regions, '\\\n",
    "        +'doi:10.7265/N5GT5K3K.', \n",
    "    'Analysis'   : 'https://github.com/chrisrwp/low-frequency-variability/'\\\n",
    "        +'blob/main/lasso/Train_CMIP6_CVDP.ipynb'\n",
    "}\n",
    "\n",
    "coefs_xr.attrs = coefs_attrs\n",
    "\n",
    "coefs_xr.to_netcdf('/glade/work/cwpowell/low-frequency-variability/'\\\n",
    "    +'lasso_coefs_scores/SIC_CVDP_Lasso_Coefs_all_CMIP6_models_'\\\n",
    "    +'1941_2014_lag_2_20_very_low_alpha_higher_it.nc')\n",
    "\n",
    "scores_attrs = coefs_attrs.copy()\n",
    "scores_attrs['Description'] = 'Multiple regression scores using the Lasso '\\\n",
    "        +'method, trained and tested on average regional sea ice '\\\n",
    "        +'thickness (SIT) and modes of climate variability for all availible '\\\n",
    "        +'CMIP6 models. Regions as defined for NSIDC '\\\n",
    "        +'MASIE-NH Version 1, modes of variability are obtained from the '\\\n",
    "        +'Climate Variability Diagnostics Package (CVDP). Training on the '\\\n",
    "        +'first 75% of members and testing on the final 15% of member for '\\\n",
    "        +'each region and month of SIC data for 1941-2014 using '\\\n",
    "        +'historical CMIP6 forcing with CVDP data lagged between 2 and 20 '\\\n",
    "        +'years for each month of the mode of variability. '\\\n",
    "        +'Hyperparameters: alpha=[0.001], random rather than '\\\n",
    "        +'cyclic Lasso model training, maximum iteration of 1e5 and a '\\\n",
    "        +'tolorence of 1e-3.', \n",
    "scores_xr.attrs = scores_attrs\n",
    "\n",
    "scores_xr.to_netcdf('/glade/work/cwpowell/low-frequency-variability/'\\\n",
    "    +'lasso_coefs_scores/SIC_CVDP_Lasso_Scores_all_CMIP6_models_'\\\n",
    "    +'1941_2014_lag_2_20_very_low_alpha.nc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NPL-3.7.9",
   "language": "python",
   "name": "npl-3.7.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
